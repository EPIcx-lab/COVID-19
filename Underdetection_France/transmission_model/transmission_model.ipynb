{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from scipy.stats import poisson\n",
    "from scipy.stats import nbinom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert region acronym: HDF\n",
      "Region selected:  Hauts-de-France\n",
      "Population: 5960000.0\n"
     ]
    }
   ],
   "source": [
    "list_regions = {'IDF': 11,'CVL':24, 'BFC':27, 'NOR': 28, 'HDF':32, 'GRE':44, 'PDL':52, 'BRE':53,\n",
    "                'NAQ':75, 'OCC':76, 'ARA':84, 'PACA':93}\n",
    "# select region\n",
    "region=input(\"Insert region acronym: \")  #e.g. IDF\n",
    "code_region = list_regions[region]\n",
    "\n",
    "# population\n",
    "df=pd.read_excel('./input/regional_pop_by_age.xlsx')\n",
    "df=df.set_index('Age')\n",
    "reg = df.loc[:,(df==code_region).any()]\n",
    "pop = reg*1000000\n",
    "pop = pop.drop('code')\n",
    "\n",
    "name_reg = pop.columns[0]\n",
    "\n",
    "N = pop.sum().iloc[0]  #total population\n",
    "\n",
    "ages = 4 #number of age classes\n",
    "\n",
    "#population per age class\n",
    "N_c = pop.iloc[0][0]   #children   [0,11) years\n",
    "N_t = pop.iloc[1][0]   #teens     [11,19)\n",
    "N_a = pop.iloc[2][0]   #adults      [19,65)\n",
    "N_s = pop.iloc[3][0]   #seniors     over 65+ \n",
    "\n",
    "print('Region selected: ', name_reg)\n",
    "print('Population:', N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epidemiological parameters\n",
    "\n",
    "incubation = 3.7       # incubation period (days) \n",
    "prodromic = 1.5        # prodromic phase (days)\n",
    "infection = 2.3        # infectious period (days)\n",
    "\n",
    "delta_t = 1   # one timestep = 1 day\n",
    "\n",
    "# compute transition rates\n",
    "sigma=1./incubation\n",
    "theta=1./prodromic\n",
    "gamma=1./infection    \n",
    "\n",
    "# fraction of asymptomatic\n",
    "asint = 0.4\n",
    "p_as = np.array([asint]*ages)\n",
    "\n",
    "#probability of developing pauci/mild/severe symptoms if not asymptomatic\n",
    "# explicit value for each age class\n",
    "ps = np.array([1.,1.,0.2,0.2])  \n",
    "ms = np.array([0.,0.,0.7,0.6])  \n",
    "ss = np.array([0.,0.,0.1,0.2])  \n",
    "\n",
    "# fraction entering I_ps, I_ms, I_ss compartments\n",
    "p_ps = np.multiply(1-p_as, ps)  \n",
    "p_ms = np.multiply(1-p_as, ms)\n",
    "p_ss = np.multiply(1-p_as, ss)\n",
    "\n",
    "# relative infectiousness\n",
    "r = np.array([0.25,0.55,0.55,0.55]) # explicit value for each age class\n",
    "\n",
    "# relative susceptibility\n",
    "susc = np.array([0.5,0.5,1,1])      # explicit value for each age class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read results of calibration\n",
    "\n",
    "# beta, lag (pre-lockdown), delay, scale_LD (during lockdown)\n",
    "\n",
    "params=pd.read_excel(\"./input/params.xlsx\")\n",
    "params=params[params[\"region\"]==code_region]\n",
    "params=params.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contact matrices\n",
    "\n",
    "#function to read matrix\n",
    "def read(df):\n",
    "    C = []\n",
    "    for i in range(ages*ages):\n",
    "        c = df[0][i]\n",
    "        C.append(c)\n",
    "    C = np.array(C)\n",
    "    C = np.reshape(C, (ages,ages))\n",
    "    return C \n",
    "\n",
    "#function to compute contact matrices w/ testing\n",
    "def extract_matrix(matrix, x_test_a,x_test_s):\n",
    "    m_p = read(matrix) # for cases in the prodromic phase\n",
    "    m_as = x_test_a*read(matrix)*0.1 + (1-x_test_a)*read(matrix) # apply testing for asymptomatic cases\n",
    "    m_t = x_test_s*read(matrix)*0.1 + (1-x_test_s)*read(matrix)  # apply testing for pauci-symptomatic and mild cases\n",
    "    m_ss = x_test_s*read(matrix)*0.1 + (1-x_test_s)*read(matrix)*0.25  # testing for severe cases\n",
    "\n",
    "    return m_p,m_as,m_t,m_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks=[20,21,22,23,24,25,26,27]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSMISSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seirh(u, parms, t, intervention, LD, exit, scale1, scale2,\n",
    "         BS_p, BS_as, BS_t, BS_ss,\n",
    "         LD_p, LD_as, LD_t, LD_ss, \n",
    "         EX_p, EX_as, EX_t, EX_ss):\n",
    "    \n",
    "    \"\"\"\n",
    "    Simulation one time step (day) of the compartmental, age-stratified model.\n",
    "    INPUT\n",
    "    u: dict containing the number of individuals (incidence and prevalence) for each compartment in the previous timestep\n",
    "    parms: list of epidemiological parameters\n",
    "    t: current timestep\n",
    "    intervention: boolean indicating if an intervention measure (e.g. lockdown) is put in place\n",
    "    LD: list containing the timesteps corresponding to start and end of lockdown\n",
    "    exit: list of lists containing the timesteps corresponding to start and end of each week after lifting lockdown\n",
    "    scale1: scaling factor of the pre-LD transmission rate, fitted during lockdown \n",
    "    scale2: scaling factor of the pre-LD transmission rate, fitted after lifting lockdown\n",
    "    BS_p, BS_as, BS_t, BS_ss: contact matrices in the pre-lockdown phase\n",
    "    LD_p, LD_as, LD_t, LD_ss: contact matrices during lockdown\n",
    "    EX_p, EX_as, EX_t, EX_ss: contact matrices in the post-lockdown phase\n",
    "    RETURNS: updated version of dict u\n",
    "    \"\"\"\n",
    "\n",
    "    #quantities of interest\n",
    "    S = u['S']\n",
    "    new_E = u['Y_E']\n",
    "    E = u['E']\n",
    "    new_I_p = u['Y_I_p']  \n",
    "    I_p = u['I_p'] \n",
    "    new_I_as = u['Y_I_as'] \n",
    "    I_as = u['I_as'] \n",
    "    new_I_ps = u['Y_I_ps'] \n",
    "    I_ps = u['I_ps'] \n",
    "    new_I_ms = u['Y_I_ms'] \n",
    "    I_ms = u['I_ms'] \n",
    "    new_I_ss = u['Y_I_ss'] \n",
    "    I_ss = u['I_ss'] \n",
    "    new_H = u['Y_H'] \n",
    "    H = u['H'] \n",
    "    new_R = u['Y_R'] \n",
    "    R = u['R'] \n",
    "    N_tot = u['N_tot'] \n",
    "\n",
    "    # epidemiological parameters\n",
    "    bet, sigm, thet, gamm, N, dt = parms\n",
    "    \n",
    "    # contact matrices\n",
    "    \n",
    "    # pre-lockdown\n",
    "    C_p = BS_p \n",
    "    C_as = BS_as\n",
    "    C_t = BS_t\n",
    "    C_ss = BS_ss        \n",
    "    \n",
    "    if intervention:\n",
    "        for i in range(len(LD)):\n",
    "            LD_start = LD[i][0]\n",
    "            LD_end = LD[i][1]\n",
    "            # during lockdown\n",
    "            if (t >= LD_start) and (t < LD_end): \n",
    "                C_p = LD_p*scale1\n",
    "                C_as = LD_as*scale1\n",
    "                C_t = LD_t*scale1\n",
    "                C_ss = LD_ss*scale1\n",
    "        for week in range(len(weeks)):\n",
    "            # post-lockdown, contact matrix changed every week\n",
    "            start_week = exit[week][0]\n",
    "            end_week = exit[week][1]\n",
    "            if (t >= start_week) and (t < end_week): \n",
    "                C_p = EX_p[week]*scale2[week]\n",
    "                C_as = EX_as[week]*scale2[week]\n",
    "                C_t = EX_t[week]*scale2[week]\n",
    "                C_ss = EX_ss[week]*scale2[week]\n",
    "                    \n",
    "    # force of infection\n",
    "    lambd = []\n",
    "    for age in range(ages):\n",
    "        l = 0 \n",
    "        for age2 in range(ages):\n",
    "            l += susc[age]*r[age2]*bet*C_p[age,age2]*I_p[age2]/N\n",
    "            l += susc[age]*r[age2]*bet*C_as[age,age2]*I_as[age2]/N\n",
    "            l += susc[age]*r[age2]*bet*C_t[age,age2]*I_ps[age2]/N\n",
    "            l += susc[age]*bet*C_t[age,age2]*I_ms[age2]/N\n",
    "            l += susc[age]*bet*C_ss[age,age2]*I_ss[age2]/N\n",
    "        lambd.append(l)\n",
    "    lambd = np.array(lambd)\n",
    "\n",
    "    # compute transition probabilities for entering in each comparment\n",
    "    in_E = 1 - np.exp(-lambd*dt)\n",
    "    in_I_p = np.array([sigm*dt]*ages)\n",
    "    in_I = np.array([thet*dt]*ages)\n",
    "    in_R = np.array([gamm*dt]*ages)\n",
    "    in_H = np.array([gamm*dt]*ages)\n",
    "    \n",
    "    # transition events (sampled by binomial or multinomial distributions with corresponding transition probabilities)\n",
    "    for age in range(ages):\n",
    "        #transitions\n",
    "        new_E[age] = np.random.binomial(S[age],in_E[age])\n",
    "        new_I_p[age] = np.random.binomial(E[age],in_I_p[age])\n",
    "        \n",
    "        trans_I = np.array([p_as[age]*in_I[age], p_ps[age]*in_I[age], p_ms[age]*in_I[age], p_ss[age]*in_I[age], 1-in_I[age]])\n",
    "        new_I_as[age], new_I_ps[age], new_I_ms[age], new_I_ss[age], res = np.random.multinomial(I_p[age],trans_I)\n",
    "        \n",
    "        recovery_as = np.random.binomial(I_as[age],in_R[age])\n",
    "        recovery_ps = np.random.binomial(I_ps[age],in_R[age])\n",
    "        recovery_ms = np.random.binomial(I_ms[age],in_R[age])\n",
    "        \n",
    "        new_H[age] = np.random.binomial(I_ss[age], in_H[age])   \n",
    "        recovery_h = np.random.binomial(H[age], in_R[age])\n",
    "                \n",
    "        new_R[age] = recovery_as + recovery_ps + recovery_ms + recovery_h \n",
    "        \n",
    "        #update compartments\n",
    "        S[age] = S[age] - new_E[age] \n",
    "        E[age] = E[age] + new_E[age] - new_I_p[age]\n",
    "        I_p[age] = I_p[age] + new_I_p[age] - new_I_as[age] - new_I_ps[age] - new_I_ms[age] - new_I_ss[age]\n",
    "        I_as[age] = I_as[age] + new_I_as[age] - recovery_as\n",
    "        I_ps[age] = I_ps[age] + new_I_ps[age] - recovery_ps\n",
    "        I_ms[age] = I_ms[age] + new_I_ms[age] - recovery_ms\n",
    "        I_ss[age] = I_ss[age] + new_I_ss[age] - new_H[age] \n",
    "        H[age] = H[age] + new_H[age] - recovery_h\n",
    "        R[age] = R[age] + new_R[age]\n",
    "        N_tot[age] = S[age]+E[age]+I_p[age]+I_as[age]+I_ps[age]+I_ms[age]+I_ss[age]+H[age]+R[age]\n",
    "   \n",
    "    return  {'t':t, 'S': S, 'E':E, 'I_p':I_p, 'I_as':I_as,'I_ps':I_ps,'I_ms':I_ms,'I_ss':I_ss,\n",
    "            'H':H,'R':R,'Y_E':new_E,'Y_I_p':new_I_p,'Y_I_as':new_I_as,\n",
    "            'Y_I_ps':new_I_ps, 'Y_I_ms':new_I_ms, 'Y_I_ss':new_I_ss, 'Y_H':new_H,'Y_R':new_R,'N_tot':N_tot}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(intervention, LD, exit, scale1, scale2,\n",
    "             BS_p, BS_as, BS_t, BS_ss,\n",
    "             LD_p, LD_as, LD_t, LD_ss, \n",
    "             EX_p, EX_as, EX_t, EX_ss):\n",
    "    \n",
    "    \"\"\"\n",
    "    Simulation of one single stochastic run of the compartmental, age-stratified model.\n",
    "    INPUT\n",
    "    intervention: boolean indicating if an intervention measure (e.g. lockdown) is put in place\n",
    "    LD: list containing the timesteps corresponding to start and end of lockdown\n",
    "    exit: list of lists containing the timesteps corresponding to start and end of each week after lifting lockdown\n",
    "    scale1: scaling factor of the pre-LD transmission rate, fitted during lockdown \n",
    "    scale2: scaling factor of the pre-LD transmission rate, fitted after lifting lockdown\n",
    "    BS_p, BS_as, BS_t, BS_ss: contact matrices in the pre-lockdown phase\n",
    "    LD_p, LD_as, LD_t, LD_ss: contact matrices during lockdown\n",
    "    EX_p, EX_as, EX_t, EX_ss: contact matrices in the post-lockdown phase\n",
    "    RETURNS: dict containing the number of individuals for each compartment, for each timestep\n",
    "    \"\"\"\n",
    "    \n",
    "    parms = [beta, sigma, theta, gamma, N, delta_t]\n",
    "    \n",
    "    tf = t_stop\n",
    "    \n",
    "    t = np.arange(tf)\n",
    "    S = np.zeros((tf,ages))\n",
    "    E = np.zeros((tf,ages))\n",
    "    I_p = np.zeros((tf,ages))   \n",
    "    I_as = np.zeros((tf,ages))\n",
    "    I_ps = np.zeros((tf,ages)) \n",
    "    I_ms = np.zeros((tf,ages))\n",
    "    I_ss = np.zeros((tf,ages))\n",
    "    H = np.zeros((tf,ages))\n",
    "    R = np.zeros((tf,ages))\n",
    "    \n",
    "    Y_E = np.zeros((tf,ages))\n",
    "    Y_I_p = np.zeros((tf,ages))\n",
    "    Y_I_as = np.zeros((tf,ages))\n",
    "    Y_I_ps = np.zeros((tf,ages))\n",
    "    Y_I_ms = np.zeros((tf,ages))\n",
    "    Y_I_ss = np.zeros((tf,ages))\n",
    "    Y_H = np.zeros((tf,ages))\n",
    "    Y_R = np.zeros((tf,ages))\n",
    "\n",
    "    N_tot = np.zeros((tf,ages))\n",
    "    \n",
    "    result = {'t':t, 'S': S, 'E':E, 'I_p':I_p, 'I_as':I_as,'I_ps':I_ps,'I_ms':I_ms,'I_ss':I_ss,\n",
    "              'H':H,'R':R,'Y_E':Y_E,'Y_I_p':Y_I_p,'Y_I_as':Y_I_as,'Y_I_ps':Y_I_ps, \n",
    "              'Y_I_ms':Y_I_ms, 'Y_I_ss':Y_I_ss,'Y_H':Y_H,'Y_R':Y_R,'N_tot':N_tot}\n",
    "\n",
    "    #initial condition\n",
    "    u = {'t':0, 'S': [N_c,N_t,N_a-I_seed,N_s], 'E':[0]*ages,'I_p':[0,0,I_seed,0],\n",
    "         'I_as':[0]*ages,'I_ps':[0]*ages,'I_ms':[0]*ages,'I_ss':[0]*ages,'H':[0]*ages,'R':[0]*ages,\n",
    "         'Y_E':[0]*ages,'Y_I_p':[0]*ages,'Y_I_as':[0]*ages,'Y_I_ps':[0]*ages, 'Y_I_ms':[0]*ages, 'Y_I_ss':[0]*ages, \n",
    "         'Y_H':[0]*ages,'Y_R':[0]*ages,'N_tot':[N_c,N_t,N_a,N_s]}   \n",
    "\n",
    "    #save initial condition\n",
    "    for c in result.keys():\n",
    "        result[c][0] = u[c]\n",
    "    \n",
    "    for j in range(1,tf):\n",
    "        #run one step of the transmission model\n",
    "        u = seirh(u,parms,t[j],intervention, LD, exit, scale1, scale2,\n",
    "                 BS_p, BS_as, BS_t, BS_ss,\n",
    "                 LD_p, LD_as, LD_t, LD_ss, \n",
    "                 EX_p, EX_as, EX_t, EX_ss)\n",
    "        #save the result \n",
    "        for c in result.keys():\n",
    "            result[c][j] = u[c]\n",
    "            \n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(intervention = False, LD = [[0,0]], \n",
    "                   scale1=0,scale2=0,x_test_a=0,x_test_s=0):\n",
    "    \n",
    "    \"\"\"\n",
    "    Simulation of multiple stochastic runs of the compartmental, age-stratified model.\n",
    "    INPUT\n",
    "    intervention: boolean indicating if an intervention measure (e.g. lockdown) is put in place\n",
    "    LD: list containing the timesteps corresponding to start and end of lockdown\n",
    "    scale1: scaling factor of the pre-LD transmission rate, fitted during lockdown \n",
    "    scale2: scaling factor of the pre-LD transmission rate, fitted after lifting lockdown\n",
    "    x_test_a: fraction of asymptomatic cases tested and put in isolation\n",
    "    x_test_s: fraction of symptomatic cases tested and put in isolation\n",
    "    RETURNS: dict containing the number of individuals for compartments of interest (e.g. incidence in the hospital compartment), for each timestep, for each run\n",
    "    \"\"\"\n",
    "    \n",
    "    out_Y_H = pd.DataFrame(np.arange(t_stop))\n",
    "    out_Y_Ias = pd.DataFrame(np.arange(t_stop))\n",
    "    out_Y_Ips = pd.DataFrame(np.arange(t_stop))    \n",
    "    out_Y_Ims = pd.DataFrame(np.arange(t_stop))    \n",
    "    out_Y_Iss = pd.DataFrame(np.arange(t_stop))    \n",
    "\n",
    "    # read matrices \n",
    "    \n",
    "    #pre-lockdown\n",
    "    BS_h = pd.read_table('./input/matrices/baseline.txt', header = None, sep=' ')\n",
    "    BS_p, BS_as, BS_t, BS_ss = extract_matrix(BS_h,x_test_a=0,x_test_s=0)\n",
    " \n",
    "    #lockdown\n",
    "    LD_h = pd.read_table('./input/matrices/LD/LD_region_'+str(code_region)+'.txt', header = None, sep=' ')\n",
    "    LD_p, LD_as, LD_t, LD_ss = extract_matrix(LD_h,x_test_a=0,x_test_s=0)\n",
    "    \n",
    "    #post-lockdown\n",
    "    EX_h={}\n",
    "    for week,ttt in enumerate(weeks):\n",
    "        path_matrix='./input/matrices/exit/region_'+str(code_region)+'_week_'+str(ttt)+'.txt'\n",
    "        EX_h[week]=pd.read_table(path_matrix, header = None, sep=' ')\n",
    "\n",
    "    one_week=7\n",
    "    TW = [[0 for col in range(2)] for row in range(len(weeks))]\n",
    "    for i in range(len(weeks)):\n",
    "        TW[i][0]=m_11+i*one_week\n",
    "        TW[i][1]=m_11+(i+1)*one_week\n",
    "    \n",
    "    EX_p={}\n",
    "    EX_as={}\n",
    "    EX_t={}\n",
    "    EX_ss={}\n",
    "    for week,ttt in enumerate(weeks):\n",
    "        EX_p[week], EX_as[week], EX_t[week], EX_ss[week] = extract_matrix(EX_h[week],x_test_a=x_test_a[week],x_test_s=x_test_s[week])\n",
    "  \n",
    "    #for each run\n",
    "    for n in range(n_runs):\n",
    "        out = simulate(intervention, LD, TW, scale1,scale2,\n",
    "                       BS_p, BS_as, BS_t, BS_ss,\n",
    "                       LD_p, LD_as, LD_t, LD_ss, \n",
    "                       EX_p, EX_as, EX_t, EX_ss)\n",
    "        # extract quantities of interest, e.g. admission to hospital, all age classes\n",
    "        # save the timeseries in the column of a dataframe         \n",
    "        out_Y_H[n] = pd.DataFrame(out['Y_H']).sum(axis=1)\n",
    "        out_Y_Ias[n] = pd.DataFrame(out['Y_I_as']).sum(axis=1)\n",
    "        out_Y_Ips[n] = pd.DataFrame(out['Y_I_ps']).sum(axis=1)\n",
    "        out_Y_Ims[n] = pd.DataFrame(out['Y_I_ms']).sum(axis=1)\n",
    "        out_Y_Iss[n] = pd.DataFrame(out['Y_I_ss']).sum(axis=1)\n",
    "        \n",
    "    return {'adm_H':out_Y_H,'new_Ias':out_Y_Ias,'new_Ips':out_Y_Ips,'new_Ims':out_Y_Ims,'new_Iss':out_Y_Iss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stop = 170 #number of (daily) timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_median_CI(DF):\n",
    "    df = DF.copy()\n",
    "    df['p1'] = df[[i for i in range(n_runs)]].quantile(0.025, axis=1)\n",
    "    df['median'] = df[[i for i in range(n_runs)]].median(axis=1)  \n",
    "    df['p2'] = df[[i for i in range(n_runs)]].quantile(0.975, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'./input/hospitalizations_by_region.csv')\n",
    "H_adm = data[data.reg==code_region][['date','hosp_obs']]\n",
    "H_adm.columns = ['date','obs']\n",
    "H_adm = H_adm.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DETECTED CASES (confirmed + imputed)\n",
    "\n",
    "detected=pd.read_csv('./input/detected_cases.csv')\n",
    "detected=detected[detected['region']==code_region]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calibration post-LD: iteration n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_seed = 10  # initial number of infected \n",
    "\n",
    "beta=params[\"beta\"][0]\n",
    "lag=params[\"lag\"][0]\n",
    "delay=params[\"delay\"][0]\n",
    "scale1=params[\"scale_LD\"][0]\n",
    "\n",
    "calendar=pd.DataFrame(pd.date_range(dt.date(2020, 3, 1)-dt.timedelta(days=int(lag)), periods=365)) \n",
    "\n",
    "# timesteps for lockdown start and end date (March 17 - May 11)\n",
    "start_ld = lag + 16  \n",
    "start =start_ld + 5\n",
    "m_11 = start_ld + 55  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert current iteration number: n= 10\n",
      "FILES NOT FOUND! I am not finding the output files of the previous iteration, so I am assuming n=0.\n"
     ]
    }
   ],
   "source": [
    "# Read 8 values in [0,1] of weekly detection probability, for sympt and asympt cases.\n",
    "# if n=0, initialize with probability = 0.5\n",
    "# if n>0, inform with the detection probability computed at timestep n-1\n",
    "\n",
    "n = int(input('Insert current iteration number: n= '))\n",
    "\n",
    "if n:\n",
    "    try:\n",
    "        test_asymp = pd.read_table('./output/region_{}_input_iteration_{}_asympt.txt'.format(code_region,n-1), header = None, sep=' ')[0].values\n",
    "        test_sympt = pd.read_table('./output/region_{}_input_iteration_{}_sympt.txt'.format(code_region,n-1), header = None, sep=' ')[0].values\n",
    "    except FileNotFoundError:\n",
    "        print ('FILES NOT FOUND! I am not finding the output files of the previous iteration, so I am assuming n=0.')\n",
    "        n = 0    \n",
    "        test_asymp, test_sympt = np.array([0.5]*8), np.array([0.5]*8)\n",
    "else:\n",
    "    test_asymp, test_sympt = np.array([0.5]*8), np.array([0.5]*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose number of stochatic runs: 5\n",
      "0.5 -inf\n",
      "0.51 -inf\n",
      "0.52 -inf\n",
      "0.53 -inf\n",
      "0.54 -inf\n",
      "0.55 -inf\n",
      "0.56 -inf\n",
      "0.5700000000000001 -inf\n",
      "0.5800000000000001 -inf\n",
      "0.5900000000000001 -inf\n",
      "0.6000000000000001 -inf\n",
      "0.6100000000000001 -inf\n",
      "0.6200000000000001 -inf\n",
      "0.6300000000000001 -inf\n",
      "0.6400000000000001 -inf\n",
      "0.6500000000000001 -inf\n",
      "0.6600000000000001 -inf\n",
      "0.6700000000000002 -inf\n",
      "0.6800000000000002 -inf\n",
      "0.6900000000000002 -inf\n",
      "0.7000000000000002 -inf\n",
      "0.7100000000000002 -inf\n",
      "0.7200000000000002 -inf\n",
      "0.7300000000000002 -inf\n",
      "0.7400000000000002 -inf\n",
      "0.7500000000000002 -inf\n",
      "0.7600000000000002 -inf\n",
      "0.7700000000000002 -inf\n",
      "0.7800000000000002 -inf\n",
      "0.7900000000000003 -inf\n",
      "0.8000000000000003 -inf\n",
      "0.8100000000000003 -inf\n",
      "0.8200000000000003 -inf\n",
      "0.8300000000000003 -inf\n",
      "0.8400000000000003 -inf\n",
      "0.8500000000000003 -inf\n",
      "0.8600000000000003 -inf\n",
      "0.8700000000000003 -inf\n",
      "0.8800000000000003 -inf\n",
      "0.8900000000000003 -inf\n",
      "0.9000000000000004 -inf\n",
      "0.9100000000000004 -inf\n",
      "0.9200000000000004 -inf\n",
      "0.9300000000000004 -inf\n",
      "0.9400000000000004 -inf\n",
      "0.9500000000000004 -inf\n",
      "0.9600000000000004 -inf\n",
      "0.9700000000000004 -inf\n",
      "0.9800000000000004 -inf\n",
      "0.9900000000000004 -inf\n",
      "1.0000000000000004 -inf\n",
      "1.0100000000000005 -inf\n",
      "1.0200000000000005 -inf\n",
      "1.0300000000000005 -inf\n",
      "1.0400000000000005 -inf\n",
      "1.0500000000000005 -inf\n",
      "1.0600000000000005 -inf\n",
      "1.0700000000000005 -175.32662555268845\n",
      "1.0800000000000005 -199.4687156507435\n",
      "1.0900000000000005 -inf\n",
      "1.1000000000000005 -inf\n",
      "1.1100000000000005 -155.32145568067108\n",
      "1.1200000000000006 -inf\n",
      "1.1300000000000006 -inf\n",
      "1.1400000000000006 -168.22901043581055\n",
      "1.1500000000000006 -157.3047864218523\n",
      "1.1600000000000006 -157.19388963052867\n",
      "1.1700000000000006 -159.5346917001178\n",
      "1.1800000000000006 -158.03744444064637\n",
      "1.1900000000000006 -159.31035761540127\n",
      "1.2000000000000006 -156.25179985679588\n",
      "1.2100000000000006 -161.9169539932339\n",
      "1.2200000000000006 -155.0234631568213\n",
      "1.2300000000000006 -156.93697549247042\n",
      "1.2400000000000007 -179.05446213612586\n",
      "1.2500000000000007 -183.58153792601138\n",
      "1.2600000000000007 -153.65380324953264\n",
      "1.2700000000000007 -177.97279258973577\n",
      "1.2800000000000007 -176.77914881199166\n",
      "1.2900000000000007 -193.78616958405016\n",
      "1.3000000000000007 -209.3108356076508\n",
      "1.3100000000000007 -263.386732424299\n",
      "1.3200000000000007 -225.90977838758178\n",
      "1.3300000000000007 -185.40498554792805\n",
      "1.3400000000000007 -188.87480994757408\n",
      "1.3500000000000008 -280.2701569290381\n",
      "1.3600000000000008 -238.7944127347497\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-41da5f33092f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m                          \u001b[0mscale1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscale1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscale2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweeks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                          \u001b[0mx_test_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_asymp\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# % testing informed from the detection probability\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                          x_test_s=test_sympt)  # % testing informed from the detection probability\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mmedian_adm_H\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_median_CI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'adm_H'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'median'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-5ff4b1d0b5d2>\u001b[0m in \u001b[0;36mrun_simulation\u001b[1;34m(intervention, LD, scale1, scale2, x_test_a, x_test_s)\u001b[0m\n\u001b[0;32m     54\u001b[0m                        \u001b[0mBS_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBS_as\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBS_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBS_ss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m                        \u001b[0mLD_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLD_as\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLD_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLD_ss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m                        EX_p, EX_as, EX_t, EX_ss)\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[1;31m# extract quantities of interest, e.g. admission to hospital, all age classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;31m# save the timeseries in the column of a dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-8710bac34d7b>\u001b[0m in \u001b[0;36msimulate\u001b[1;34m(intervention, LD, exit, scale1, scale2, BS_p, BS_as, BS_t, BS_ss, LD_p, LD_as, LD_t, LD_ss, EX_p, EX_as, EX_t, EX_ss)\u001b[0m\n\u001b[0;32m     63\u001b[0m                  \u001b[0mBS_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBS_as\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBS_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBS_ss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                  \u001b[0mLD_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLD_as\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLD_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLD_ss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                  EX_p, EX_as, EX_t, EX_ss)\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;31m#save the result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-0eafa4ee6e78>\u001b[0m in \u001b[0;36mseirh\u001b[1;34m(u, parms, t, intervention, LD, exit, scale1, scale2, BS_p, BS_as, BS_t, BS_ss, LD_p, LD_as, LD_t, LD_ss, EX_p, EX_as, EX_t, EX_ss)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;31m#transitions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mnew_E\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mage\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0min_E\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[0mnew_I_p\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mage\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0min_I_p\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit scaling factor of current iteration\n",
    "\n",
    "lh = pd.DataFrame({'scale': [],'loglike': []})\n",
    "\n",
    "n_runs = int(input('Choose number of stochatic runs: ')) #500 stochastic runs were used in the paper\n",
    "\n",
    "scales = np.arange(0.5, 2.5, 0.01)  #explore values of the scaling factor  \n",
    "for s in scales:\n",
    "    output = run_simulation(intervention=True,LD=[[start+delay,m_11]],\n",
    "                         scale1=scale1,scale2=[s for i in range(len(weeks))],\n",
    "                         x_test_a=test_asymp,  # % testing informed from the detection probability\n",
    "                         x_test_s=test_sympt)  # % testing informed from the detection probability\n",
    "    median_adm_H = add_median_CI(output['adm_H'])['median']\n",
    "    p=0\n",
    "    for t in range(71,len(H_adm['obs'])): #from May 11\n",
    "        #compute log likelihood\n",
    "        p += poisson.logpmf(H_adm['obs'].iloc[t], mu=median_adm_H.iloc[t+lag])\n",
    "    print(s,p)\n",
    "    lh = lh.append({'scale':s, 'loglike':p}, ignore_index=True)\n",
    "    \n",
    "lh.to_csv('./output/region_{}_iteration_{}_fit_scaling_factor.csv'.format(code_region,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8400000000000003"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read results\n",
    "lh = pd.read_csv('./output/region_{}_iteration_{}_fit_scaling_factor.csv'.format(code_region,n).format(n), index_col=0)\n",
    "#take the maximum likelihood estimator\n",
    "scale_exit=lh.iloc[lh['loglike'].idxmax()]['scale']\n",
    "scale_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMULATION iteration n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose number of stochatic runs: 5\n"
     ]
    }
   ],
   "source": [
    "n_runs = int(input('Choose number of stochatic runs: ')) #500 stochastic runs were used in the paper\n",
    "\n",
    "output = run_simulation(intervention=True,LD=[[start+delay,m_11]],\n",
    "                        scale1=scale1,scale2=[scale_exit for i in range(len(weeks))],\n",
    "                        x_test_a=test_asymp,\n",
    "                        x_test_s=test_sympt) \n",
    "\n",
    "#extract number of new infections and new hospital admissions\n",
    "incidence_I_as = output['new_Ias'].copy()\n",
    "incidence_I_ps = output['new_Ips'].copy()\n",
    "incidence_I_ms = output['new_Ims'].copy()    \n",
    "incidence_I_ss = output['new_Iss'].copy()\n",
    "\n",
    "ddf = output['adm_H'].copy()\n",
    "ddf = add_median_CI(ddf)\n",
    "incidence_H = ddf.copy()\n",
    "\n",
    "calendar = pd.DataFrame(pd.date_range(dt.date(2020, 3, 1)-dt.timedelta(days=int(lag)), periods=len(incidence_H)))\n",
    "incidence_H['time']=calendar\n",
    "incidence_H['region']=code_region\n",
    "gg = incidence_H.copy()\n",
    "gg2 = gg[gg['time']<='2020-07-05']\n",
    "gg2.to_csv('./output/region_'+str(code_region)+'_iteration_'+str(n)+'_admissions_H.csv')\n",
    "\n",
    "sympt_inf =incidence_I_ss+incidence_I_ms+incidence_I_ps\n",
    "asympt_inf =incidence_I_as\n",
    "\n",
    "#compute detection probability\n",
    "\n",
    "#asymptomatic infections\n",
    "df=asympt_inf.copy()\n",
    "df['date']=calendar\n",
    "df2=df[(df['date']>='2020-05-11') & (df['date']<='2020-07-05')].copy()\n",
    "df2['week']= df2['date'].apply(lambda x: x.week)\n",
    "df3=df2.groupby('week').sum().reset_index()\n",
    "df4 = add_median_CI(df3)\n",
    "df4['detected_cases']=detected['asympt'].values #asymptomatic\n",
    "df4['detection_rate_median']=(df4['detected_cases']/df4['median'])\n",
    "df4['detection_rate_p1']=(df4['detected_cases']/df4['p1'])\n",
    "df4['detection_rate_p2']=(df4['detected_cases']/df4['p2'])\n",
    "df4[['week','detection_rate_median','detection_rate_p1','detection_rate_p2']].to_csv('./output/region_'+str(code_region)+'_iteration_'+str(n)+'_detection_rate_asympt.csv', index=False)\n",
    "\n",
    "#symptomatic infections\n",
    "df=sympt_inf.copy()\n",
    "df['date']=calendar\n",
    "df2=df[(df['date']>='2020-05-11') & (df['date']<='2020-07-05')].copy()\n",
    "df2['week']= df2['date'].apply(lambda x: x.week)\n",
    "df3=df2.groupby('week').sum().reset_index()\n",
    "df4 = add_median_CI(df3)\n",
    "df4['detected_cases']=detected['sympt'].values #symptomatic\n",
    "df4['detection_rate_median']=(df4['detected_cases']/df4['median'])\n",
    "df4['detection_rate_p1']=(df4['detected_cases']/df4['p1'])\n",
    "df4['detection_rate_p2']=(df4['detected_cases']/df4['p2'])\n",
    "df4[['week','detection_rate_median','detection_rate_p1','detection_rate_p2']].to_csv('./output/region_'+str(code_region)+'_iteration_'+str(n)+'_detection_rate_sympt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results as input for the next iteration (n+1)\n",
    "sympt=pd.read_csv('./output/region_'+str(code_region)+'_iteration_'+str(n)+'_detection_rate_sympt.csv')\n",
    "asymp=pd.read_csv('./output/region_'+str(code_region)+'_iteration_'+str(n)+'_detection_rate_asympt.csv')\n",
    "np.savetxt('./output/region_{}_input_iteration_{}_sympt.txt'.format(code_region,n+1), sympt['detection_rate_median'].values)\n",
    "np.savetxt('./output/region_{}_input_iteration_{}_asympt.txt'.format(code_region,n+1), asymp['detection_rate_median'].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
